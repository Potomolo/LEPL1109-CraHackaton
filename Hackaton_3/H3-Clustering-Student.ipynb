{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5  color=#003366> <b>[LEPL1109] - STATISTICS AND DATA SCIENCES</b> <br><br> \n",
    "<b>Hackathon 03 - Clustering: Bias in sensitive datasets</b> </font> <br><br><br>\n",
    "\n",
    "<font size=4  color=#003366>\n",
    "Prof. D. Hainaut<br>\n",
    "Prof. L. Jacques<br>\n",
    "\n",
    "<br><br>\n",
    "Adrien Banse (adrien.banse@uclouvain.be)<br>\n",
    "Jana Jovcheva (jana.jovcheva@uclouvain.be)<br>\n",
    "François Lessage (francois.lessage@uclouvain.be)<br>\n",
    "Sofiane Tanji (sofiane.tanji@uclouvain.be)<br>\n",
    "<div style=\"text-align: right\"> Version 2024-2025</div>\n",
    "<br><br>\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>[IMPORTANT] Read all the documentation</b>  <br>\n",
    "    Make sure that you read the whole notebook, <b>and</b> the <code>README.md</code> file in the folder.\n",
    "</div>\n",
    "<br><br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Guidelines and Deliverables**\n",
    "\n",
    "*   This hackathon is due on the **22 December 2024 at 22h00**\n",
    "*   Copying code or answers from other groups (or from the internet) is strictly forbidden. <b>Each source of inspiration (stack overflow, git, other groups, ChatGPT...) must be clearly indicated!</b>\n",
    "*  This notebook (with the \"ipynb\" extension) file, the report (PDF format) and all other files that are necessary to run your code must be delivered on <b>Moodle</b>.\n",
    "* Only the PDF report and the python source file will be graded, both on their content and the quality of the text / figures.\n",
    "  * 5/10 for the code.\n",
    "  * 4/10 for the Latex report.\n",
    "  * 1/10 for the visualization. <br><br>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>[DELIVERABLE] Summary</b>  <br>\n",
    "After the reading of this document (and playing with the code!), we expect you to provide us with:\n",
    "<ol>\n",
    "   <li> a PDF file (written in LaTeX) that answers all the questions below. The report should contain high quality figures with named axes (we recommend saving plots with the <samp>.pdf</samp> extension);\n",
    "   <li> this Jupyter Notebook (it will be read, checked for plagiarism and evaluated);\n",
    "   <li> and all other files we would need to run your code.\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "As mentioned above, plagiarism is forbidden. However, we cannot forbid you to use artificial intelligence BUT we remind you that the aim of this project is to learn on your own and with the help of the course material. Finally, we remind you that for the same question, artificial intelligence presents similar solutions, which could be perceived as a form of plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Context & Objective**\n",
    "\n",
    "## Context\n",
    "\n",
    "Predictive algorithms serve multiple functions in criminal justice. They forecast crime locations, identify potential violent offenders, predict court appearance compliance, and estimate recidivism risk. \n",
    "COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) stands as a prominent risk assessment tool. Since 1998, the COMPAS risk score has been used by many jurisdictions in the United States to assess risk of recidivism in pre-trial bail decisions.\n",
    "In the United States, a defendant may either be detained or released on bail *(sous caution)* prior to the trial in court depending on various factors. Judges may detain defendants or increase the bail amount based on the risk score provided by the COMPAS algorithm.\n",
    "\n",
    "\n",
    "In 2016, investigative journalists at ProPublica published [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing), highlighting significant biases in the COMPAS Algorithm. Specifically, they showed that the proportion of false positives for African-American defendants is significantly higher than for Caucasian defendants. In other words, more African-American were labeled high risk and ended up not relapsing into criminal behaviour than Caucasian defendants. A more thorough explanation of their data analysis procedure can be found in their companion article [How We Analyzed the COMPAS Recidivism Algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm).\n",
    "\n",
    "The COMPAS algorithm is proprietary software. What is known is that its decision is based on the answers to a questionnaire with 137 questions which the defendant must fill. There are questions related to crime (“How many prior juvenile felony offense arrests?”) along with seemingly mundane ones (“Do you live with friends?”; “Do you feel discouraged at times?”).\n",
    "\n",
    "In this hackathon, you are provided a dataset with a subset of answers to that questionnaire from more than 7000 defendants living in Broward County, Florida as well as whether they did relapse into criminal behaviour or not.\n",
    "\n",
    "## Objective(s)\n",
    "It has been shown in the article linked above that the COMPAS algorithm is biased. We take this for granted and we do not bother to show it again. The main objective of the hackathon for you is to understand that it is not only the COMPAS algorithm that is biased, but that **the data itself is biased**, in the sense that one can find structural patterns of discrimination embedded in the data. In other words, *learning from data coming from a biased world without precautions will necessarily lead to biased predictions*. Knowing which precautions one should take to avoid biased predictions is a whole subfield of machine learning called \"Fairness in AI\". It is out of the scope of this hackathon and out of the scope of LEPL1109. If you are curious about it however, a great resource is the following book [Fairness and machine learning Limitations and Opportunities](https://fairmlbook.org/).\n",
    "\n",
    "To see that the data itself is biased, you will implement your own recidivism prediction algorithms and measure their fairness.\n",
    "\n",
    "## Dataset description\n",
    "A large part of this hackathon will be devoted to handling, understanding and manipulating the dataset. The dataset provided represents 7214 defendants (data points) with 49 answers to the questionnaire (features) for each defendant. This is a lot of features and it should take you some time to understand them before going through Part 1. This data processing part may be tiresome but it is a necessary task in any serious data project.\n",
    "A description of the features is provided in the table below:\n",
    "\n",
    "| Feature               | Description                                                                                      |\n",
    "|-----------------------|--------------------------------------------------------------------------------------------------|\n",
    "| name                  | Full name of the defendant                                                                       |\n",
    "| first                 | First name of the defendant                                                                      |\n",
    "| last                  | Last name of the defendant                                                                       |\n",
    "| compas_screening_date | The date the defendant filled the questionnaire                                                  |\n",
    "| sex                   | Sex of the defendant (Female, Male)                                                              |\n",
    "| dob                   | Date of birth of the defendant (YYYY-MM-DD)                                                      |\n",
    "| age                   | Age of the defendant                                                                             |\n",
    "| age_cat               | Age category of the defendant (Less than 25, 25-45, Greater than 45)                             |\n",
    "| race                  | race attribute (African-American, Caucasian, Hispanic, Asian, Native American, Other)       |\n",
    "| juv_fel_count         | Number of juvenile felonies committed by the defendant                                           |\n",
    "| decile_score          | Decile of the COMPAS score                                                                       |\n",
    "| juv_misd_count        | Number of juvenile misdemeanors                                                                  |\n",
    "| juv_other_count       | Number of juvenile convictions that are not considered misdemeanors nor felonies                 |\n",
    "| priors_count          | Number of prior crimes committed                                                                 |\n",
    "| days_b_screening_arrest | Count of days between screening date and (original) arrest date                                |\n",
    "| c_jail_in             | Datetime at which the defendant entered jail (YYYY-MM-DD, hh:mm:ss)                              |\n",
    "| c_jail_out            | Datetime at which the defendant left jail (YYYY-MM-DD, hh:mm:ss)                                 |\n",
    "| c_case_number         | Case number for the current charge                                                               |\n",
    "| c_offense_date        | Date the offense was committed (YYYY-MM-DD)                                                      |\n",
    "| c_arrest_date         | Date the offense was arrested (YYYY-MM-DD)                                                       |\n",
    "| c_days_from_compas    | Days from COMPAS screening date to current arrest date                                           |\n",
    "| c_charge_degree       | Current charge degree (felony or misdemeanor) at the time of filling the questionnaire (\"F\", \"M\")|\n",
    "| c_charge_desc         | Description of the current charge                                                                |\n",
    "| is_recid              | Binary variable indicating whether the defendant is rearrested at any time (0, 1)                |\n",
    "| r_case_number         | Case number for a recidivism charge                                                              |\n",
    "| r_charge_degree       | Recidivism charge degree (felony or misdemeanor) for an offense subsequent to filling the questionnaire |\n",
    "| r_days_from_arrest    | Days from Arrest to Recidivism Event                                                             |\n",
    "| r_offense_date        | Date the recidivism offense was committed (YYYY-MM-DD)                                           |\n",
    "| r_charge_desc         | Description of the recidivism charge                                                             |\n",
    "| r_jail_in             | Datetime at which the defendant entered jail for a recidivism charge (YYYY-MM-DD, hh:mm:ss)      |\n",
    "| r_jail_out            | Datetime at which the defendant left jail for a recidivism charge (YYYY-MM-DD, hh:mm:ss)         |\n",
    "| violent_recid         | Number of violent recidivism events                                                              |\n",
    "| is_violent_recid      | Binary variable indicating whether the defendant committed a violent recidivism (0, 1)           |\n",
    "| vr_case_number        | Case number for a violent recidivism charge                                                      |\n",
    "| vr_charge_degree      | Violent recidivism charge degree (felony or misdemeanor)                                         |\n",
    "| vr_offense_date       | Date the violent recidivism offense was committed (YYYY-MM-DD)                                   |\n",
    "| vr_charge_desc        | Description of the violent recidivism charge                                                     |\n",
    "| type_of_assessment    | Type of COMPAS assessment performed                                                              |\n",
    "| decile_score.1        | *Same as decile_score*                                                                           |\n",
    "| score_text            | Recidivism risk of the defendant (Low, Medium, High)                                             |\n",
    "| screening_date        | Date on which the defendant was screened (YYYY-MM-DD)                                            |\n",
    "| v_type_of_assessment  | Type of violent risk assessment                                                                  |\n",
    "| v_decile_score        | Decile score for violent risk assessment                                                         |\n",
    "| v_score_text          | Violent recidivism risk of the defendant (Low, Medium, High)                                     |\n",
    "| v_screening_date      | Date of the violent risk assessment (YYYY-MM-DD)                                                 |\n",
    "| in_custody            | Date on which the defendant was placed in custody (YYYY-MM-DD)                                   |\n",
    "| out_custody           | Date on which the defendant left custody (YYYY-MM-DD)                                            |\n",
    "| priors_count.1        | *Same as priors_count*                                                                           |\n",
    "| two_year_recid        | Binary variable on whether the defendant has recidivated within two years (0, 1)                 |\n",
    "\n",
    "## **Notebook structure**\n",
    "\n",
    "### PART 1 - Data preprocessing\n",
    "   #### 1.1 - Importing the packages\n",
    "   #### 1.2 - Importing the dataset\n",
    "   #### 1.3 - Dataset curation\n",
    "   #### 1.4 - Feature engineering\n",
    "   #### 1.5 - Sensitive features\n",
    "   #### 1.6 - Scale the dataset\n",
    "\n",
    "### PART 2 - Data exploration\n",
    "   #### 2.1 - Feature visualization\n",
    "   #### 2.2 - Principal Component Analysis\n",
    "\n",
    "   \n",
    "### PART 3 - Clustering\n",
    "   #### 3.1 - K-Means\n",
    "   #### 3.2 - Results Analysis\n",
    "\n",
    "\n",
    "### PART 4 - Validation and fairness metrics\n",
    "   #### 4.1 - Silhouette score\n",
    "   #### 4.2 - Purity and entropy of a clustering\n",
    "   #### 4.3 - Precision and Recall per race group\n",
    "   #### 4.4 - Select the number of clusters\n",
    "\n",
    "\n",
    "### PART 5 - Visualization\n",
    "   #### 5.1 - Visualize your results\n",
    "\n",
    "<br><br>\n",
    "\n",
    "***Remark***\n",
    "\n",
    "We filled this notebook with preliminary (trivial) code. This practice makes possible to run each cell, even the last ones, without throwing warnings once the dataset is imported. <b>Take advantage of this aspect to divide the work between all team members!</b> <br><br>\n",
    "Remember that many libraries exist in Python, so many functions have already been developed. Read the documentation and don't reinvent the wheel! You can import whatever you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=7 color=#009999> <b>PART I - Preliminaries</b> </font> <br><br>\n",
    "\n",
    "<font size=5 color=#009999> <b>1.1 - Importing the packages</b> <br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°1.1 : IMPORTING ALL THE NECESSARY PACKAGES\n",
    "\n",
    "@pre:  /\n",
    "@post: The necessary packages should be loaded.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import all the necessary packages here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>1.2 - Importing the dataset</b> <br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7214 entries, 0 to 7213\n",
      "Data columns (total 49 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   name                     7214 non-null   object \n",
      " 1   first                    7214 non-null   object \n",
      " 2   last                     7214 non-null   object \n",
      " 3   compas_screening_date    7214 non-null   object \n",
      " 4   sex                      7214 non-null   object \n",
      " 5   dob                      7214 non-null   object \n",
      " 6   age                      7214 non-null   int64  \n",
      " 7   age_cat                  7214 non-null   object \n",
      " 8   race                     7214 non-null   object \n",
      " 9   juv_fel_count            7214 non-null   int64  \n",
      " 10  decile_score             7214 non-null   int64  \n",
      " 11  juv_misd_count           7214 non-null   int64  \n",
      " 12  juv_other_count          7214 non-null   int64  \n",
      " 13  priors_count             7214 non-null   int64  \n",
      " 14  days_b_screening_arrest  6907 non-null   float64\n",
      " 15  c_jail_in                6907 non-null   object \n",
      " 16  c_jail_out               6907 non-null   object \n",
      " 17  c_case_number            7192 non-null   object \n",
      " 18  c_offense_date           6055 non-null   object \n",
      " 19  c_arrest_date            1137 non-null   object \n",
      " 20  c_days_from_compas       7192 non-null   float64\n",
      " 21  c_charge_degree          7214 non-null   object \n",
      " 22  c_charge_desc            7185 non-null   object \n",
      " 23  is_recid                 7214 non-null   int64  \n",
      " 24  r_case_number            3471 non-null   object \n",
      " 25  r_charge_degree          3471 non-null   object \n",
      " 26  r_days_from_arrest       2316 non-null   float64\n",
      " 27  r_offense_date           3471 non-null   object \n",
      " 28  r_charge_desc            3413 non-null   object \n",
      " 29  r_jail_in                2316 non-null   object \n",
      " 30  r_jail_out               2316 non-null   object \n",
      " 31  violent_recid            0 non-null      float64\n",
      " 32  is_violent_recid         7214 non-null   int64  \n",
      " 33  vr_case_number           819 non-null    object \n",
      " 34  vr_charge_degree         819 non-null    object \n",
      " 35  vr_offense_date          819 non-null    object \n",
      " 36  vr_charge_desc           819 non-null    object \n",
      " 37  type_of_assessment       7214 non-null   object \n",
      " 38  decile_score.1           7214 non-null   int64  \n",
      " 39  score_text               7214 non-null   object \n",
      " 40  screening_date           7214 non-null   object \n",
      " 41  v_type_of_assessment     7214 non-null   object \n",
      " 42  v_decile_score           7214 non-null   int64  \n",
      " 43  v_score_text             7214 non-null   object \n",
      " 44  v_screening_date         7214 non-null   object \n",
      " 45  in_custody               6978 non-null   object \n",
      " 46  out_custody              6978 non-null   object \n",
      " 47  priors_count.1           7214 non-null   int64  \n",
      " 48  two_year_recid           7214 non-null   int64  \n",
      "dtypes: float64(4), int64(12), object(33)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.2 : IMPORTING THE DATASET\n",
    "\n",
    "@pre:  /\n",
    "@post: The object `df` should contain a Pandas DataFrame corresponding to the file `compas-dataset.csv`.\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df = pd.read_csv(\"compas-dataset.csv\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDelete :\n",
    "\n",
    "c_arrest date\n",
    "\n",
    "c_offense date\n",
    "\n",
    "r_case number\n",
    "\n",
    "r_charge_degree\n",
    "\n",
    "r_days_from arrest\n",
    "\n",
    "r_offense_date\n",
    "\n",
    "r_charge_desc\n",
    "\n",
    "r_jail_in\n",
    "\n",
    "r_jail_out\n",
    "\n",
    "violent_recid\n",
    "\n",
    "vr_case_number \n",
    "\n",
    "vr_charge_degree\n",
    "\n",
    "vr_offense_date\n",
    "\n",
    "vr_charge_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>1.3 - Dataset curation</b> <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this hackathon, your goal is to **determine the risk of recidivism of an individual**. Therefore, you should be able to determine which features are useful for your application and remove the unnecessary ones. We provide a list of features to keep and ask you to add features to that list. This step may take more time than the others. It is important to carefully analyze each feature and its relevance for our goal.\n",
    "\n",
    "In this data cleaning task, you must remove redundant features, features that are not quantifiable and features that you believe are not linked to risk of recidivism. Yous should neither limit yourself to the provided list which is too short nor add all numeric features.\n",
    "You should also avoid data leakage. Except for the \"two_year_recid\" feature, do not keep features which represent true recidivism. For similar reasons, do not keep features linked to the predictions made by the COMPAS algorithm. Using predictions made by a supervised algorithm (which is trained using both the features matrix and the target variable) is effectively leaking information from the target variable.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 1.1] Removing unnecessary features </b>  <br>\n",
    "Can you already, a priori, detect that some features are useless?\n",
    "<ol>\n",
    "   <li> if yes, list those (useless) features and explain your choice;\n",
    "   <li> if not, then explain why it is better to wait.\n",
    "</ol>\n",
    "    Generally speaking, is it a good idea to remove a feature based on <i>a priori</i> knowledge, or doesn't it alter the final outcome?\n",
    "</div>\n",
    "\n",
    "| Feature               | Description                                                                                      |\n",
    "|-----------------------|--------------------------------------------------------------------------------------------------|\n",
    "| USELESS ~~name~~                  | ~~Full name of the defendant~~                                                                       |\n",
    "| USELESS ~~first~~                 | ~~First name of the defendant~~                                                                      |\n",
    "| USELESS ~~last~~                  | ~~Last name of the defendant~~                                                                       |\n",
    "| compas_screening_date (To Merge) | The date the defendant filled the questionnaire                                                  |\n",
    "| sex                   | Sex of the defendant (Female, Male)                                                              |\n",
    "| dob (To Merge)                   | Date of birth of the defendant (YYYY-MM-DD)                                                      |\n",
    "| age                   | Age of the defendant                                                                             |\n",
    "| REDUNDANCY ~~age_cat~~               | Age category of the defendant (Less than 25, 25-45, Greater than 45)                             |\n",
    "| race                  | race attribute (African-American, Caucasian, Hispanic, Asian, Native American, Other)       |\n",
    "| juv_fel_count         | Number of juvenile felonies committed by the defendant                                           |\n",
    "| COMPAS FORBIDDEN~~decile_score~~          | Decile of the COMPAS score                                                                       |\n",
    "| juv_misd_count        | Number of juvenile misdemeanors                                                                  |\n",
    "| juv_other_count       | Number of juvenile convictions that are not considered misdemeanors nor felonies                 |\n",
    "| priors_count          | Number of prior crimes committed                                                                 |\n",
    "| days_b_screening_arrest | Count of days between screening date and (original) arrest date                                |\n",
    "| TO MERGE START        |                                                                                                  |\n",
    "| c_jail_in   (To Merge)          | Datetime at which the defendant entered jail (YYYY-MM-DD, hh:mm:ss)                              |\n",
    "| c_jail_out  (To Merge)          | Datetime at which the defendant left jail (YYYY-MM-DD, hh:mm:ss)                                 |\n",
    "| TO MERGE END          |                                                                                                  |\n",
    "| IRRELEVANT~~c_case_number~~         | Case number for the current charge                                                               |\n",
    "| TOOMNAN~~c_offense_date~~        | Date the offense was committed (YYYY-MM-DD)                                                      |\n",
    "| TOOMNAN~~c_arrest_date~~         | Date the offense was arrested (YYYY-MM-DD)                                                       |\n",
    "| c_days_from_compas     | Days from COMPAS screening date to current arrest date                                           |\n",
    "| c_charge_degree       | Current charge degree (felony or misdemeanor) at the time of filling the questionnaire (\"F\", \"M\")|\n",
    "| IRRELEVANT~~c_charge_desc~~         | Description of the current charge                                                                |\n",
    "| ??~~is_recid~~              | Binary variable indicating whether the defendant is rearrested at any time (0, 1)                |\n",
    "| IRRELEVANT~~r_case_number~~         | Case number for a recidivism charge                                                              |\n",
    "| TOOMNAN~~r_charge_degree~~       | Recidivism charge degree (felony or misdemeanor) for an offense subsequent to filling the questionnaire |\n",
    "| TOOMNAN~~r_days_from_arrest~~    | Days from Arrest to Recidivism Event                                                             |\n",
    "| TOOMNAN~~r_offense_date~~        | Date the recidivism offense was committed (YYYY-MM-DD)                                           |\n",
    "| TOOMNAN~~r_charge_desc~~         | Description of the recidivism charge                                                             |\n",
    "| TOOMNAN~~r_jail_in~~             | Datetime at which the defendant entered jail for a recidivism charge (YYYY-MM-DD, hh:mm:ss)      |\n",
    "| TOOMNAN~~r_jail_out~~            | Datetime at which the defendant left jail for a recidivism charge (YYYY-MM-DD, hh:mm:ss)         |\n",
    "| TOOMNAN~~violent_recid~~         | Number of violent recidivism events                                                              |\n",
    "| is_violent_recid      | Binary variable indicating whether the defendant committed a violent recidivism (0, 1)           |\n",
    "| TOOMNAN~~vr_case_number~~        | Case number for a violent recidivism charge                                                      |\n",
    "| TOOMNAN~~vr_charge_degree~~      | Violent recidivism charge degree (felony or misdemeanor)                                         |\n",
    "| TOOMNAN~~vr_offense_date~~       | Date the violent recidivism offense was committed (YYYY-MM-DD)                                   |\n",
    "| TOOMNAN~~vr_charge_desc~~        | Description of the violent recidivism charge                                                     |\n",
    "| type_of_assessment    | Type of COMPAS assessment performed                                                              |\n",
    "| FORBIDDEN~~decile_score.1~~        | *Same as decile_score*                                                                           |\n",
    "| FORBIDDEN~~score_text~~            | Recidivism risk of the defendant (Low, Medium, High)                                             |\n",
    "| screening_date  (To Merge)      | Date on which the defendant was screened (YYYY-MM-DD)                                            |\n",
    "| v_type_of_assessment  | Type of violent risk assessment                                                                  |\n",
    "| FORBIDDEN ~~v_decile_score~~        | Decile score for violent risk assessment                                                         |\n",
    "| FORBIDDEN ~~v_score_text~~          | Violent recidivism risk of the defendant (Low, Medium, High)                                     |\n",
    "| v_screening_date  (To merge)    | Date of the violent risk assessment (YYYY-MM-DD)                                                 |\n",
    "| in_custody     (To Merge)       | Date on which the defendant was placed in custody (YYYY-MM-DD)                                   |\n",
    "| out_custody    (To Merge)       | Date on which the defendant left custody (YYYY-MM-DD)                                            |\n",
    "| priors_count.1        | *Same as priors_count*                                                                           |\n",
    "| OBJECTIF two_year_recid        | Binary variable on whether the defendant has recidivated within two years (0, 1)                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this hackathon, your goal is to **determine the risk of recidivism of an individual**. Therefore, you should be able to determine which features are useful for your application and remove the unnecessary ones. We provide a list of features to keep and ask you to add features to that list. This step may take more time than the others. It is important to carefully analyze each feature and its relevance for our goal.\n",
    "\n",
    "In this data cleaning task, you must remove redundant features, features that are not quantifiable and features that you believe are not linked to risk of recidivism. Yous should neither limit yourself to the provided list which is too short nor add all numeric features.\n",
    "You should also avoid data leakage. Except for the \"two_year_recid\" feature, do not keep features which represent true recidivism. For similar reasons, do not keep features linked to the predictions made by the COMPAS algorithm. Using predictions made by a supervised algorithm (which is trained using both the features matrix and the target variable) is effectively leaking information from the target variable.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 1.1] Removing unnecessary features </b>  <br>\n",
    "Can you already, a priori, detect that some features are useless?\n",
    "<ol>\n",
    "   <li> if yes, list those (useless) features and explain your choice;\n",
    "   <li> if not, then explain why it is better to wait.\n",
    "</ol>\n",
    "    Generally speaking, is it a good idea to remove a feature based on <i>a priori</i> knowledge, or doesn't it alter the final outcome?\n",
    "</div>\n",
    "\n",
    "| Feature               | Description                                                                                      |\n",
    "|-----------------------|--------------------------------------------------------------------------------------------------|\n",
    "| compas_screening_date (To Merge) | The date the defendant filled the questionnaire                                                  |\n",
    "| sex                   | Sex of the defendant (Female, Male)                                                              |\n",
    "| dob (To Merge)                   | Date of birth of the defendant (YYYY-MM-DD)                                                      |\n",
    "| age                   | Age of the defendant                                                                             |\n",
    "| race                  | race attribute (African-American, Caucasian, Hispanic, Asian, Native American, Other)       |\n",
    "| juv_fel_count         | Number of juvenile felonies committed by the defendant                                           |\n",
    "| juv_misd_count        | Number of juvenile misdemeanors                                                                  |\n",
    "| juv_other_count       | Number of juvenile convictions that are not considered misdemeanors nor felonies                 |\n",
    "| priors_count          | Number of prior crimes committed                                                                 |\n",
    "| days_b_screening_arrest | Count of days between screening date and (original) arrest date                                |\n",
    "| c_jail_in   (To Merge)          | Datetime at which the defendant entered jail (YYYY-MM-DD, hh:mm:ss)                              |\n",
    "| c_jail_out  (To Merge)          | Datetime at which the defendant left jail (YYYY-MM-DD, hh:mm:ss)                                 |\n",
    "| c_days_from_compas     | Days from COMPAS screening date to current arrest date                                           |\n",
    "| c_charge_degree       | Current charge degree (felony or misdemeanor) at the time of filling the questionnaire (\"F\", \"M\")|\n",
    "| ??~~is_recid~~              | Binary variable indicating whether the defendant is rearrested at any time (0, 1)                |\n",
    "| is_violent_recid      | Binary variable indicating whether the defendant committed a violent recidivism (0, 1)           |\n",
    "| type_of_assessment    | Type of COMPAS assessment performed                                                              |\n",
    "| screening_date  (To Merge)      | Date on which the defendant was screened (YYYY-MM-DD)                                            |\n",
    "| v_type_of_assessment  | Type of violent risk assessment                                                                  |\n",
    "| v_screening_date  (To merge)    | Date of the violent risk assessment (YYYY-MM-DD)                                                 |\n",
    "| in_custody     (To Merge)       | Date on which the defendant was placed in custody (YYYY-MM-DD)                                   |\n",
    "| out_custody    (To Merge)       | Date on which the defendant left custody (YYYY-MM-DD)                                            |\n",
    "| priors_count.1        | *Same as priors_count*                                                                           |\n",
    "| OBJECTIF two_year_recid        | Binary variable on whether the defendant has recidivated within two years (0, 1)                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°1.3.1 : CURATION OF THE DATASET\n",
    "\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset\n",
    "@post: A pandas.DataFrame `df` containing the dataset without outliers and with necessary features only\n",
    "\"\"\"\n",
    "\n",
    "# We also provide some code to remove outliers.\n",
    "df = df[\n",
    "    (\n",
    "        df[\"is_recid\"] != -1\n",
    "    )  # Data aggregator encoded is_recid = -1 whenever they couldn't find a COMPAS case.\n",
    "    & (\n",
    "        df[\"days_b_screening_arrest\"] <= 30\n",
    "    )  # More than 30 days between the day of arrest and the date when the questionnaire was filled => poor data quality\n",
    "    & (df[\"days_b_screening_arrest\"] >= -30)  # Same as above\n",
    "    & (\n",
    "        df[\"c_charge_degree\"] != \"O\"\n",
    "    )  # These are simple traffic offenses, they will never be charged with jail.\n",
    "]\n",
    "\n",
    "# For reasons made explicit later, keep at least these columns.\n",
    "# We add to the list features without missing datas and without data leakage\n",
    "# We will remove features with low correlation later on\n",
    "columns_to_keep = [\n",
    "    \"compas_screening_date\",\n",
    "    \"sex\",\n",
    "    \"dob\",\n",
    "    \"age\",\n",
    "    \"race\",\n",
    "    \"juv_fel_count\",\n",
    "    \"juv_misd_count\",\n",
    "    \"juv_other_count\",\n",
    "    \"priors_count\",\n",
    "    \"days_b_screening_arrest\",\n",
    "    \"c_jail_in\",\n",
    "    \"c_jail_out\",\n",
    "    \"c_days_from_compas\",\n",
    "    \"c_charge_degree\",\n",
    "    \"is_violent_recid\",\n",
    "    \"type_of_assessment\",\n",
    "    \"screening_date\",\n",
    "    \"v_type_of_assessment\",\n",
    "    \"v_screening_date\",\n",
    "    \"in_custody\",\n",
    "    \"out_custody\",\n",
    "    \"priors_count.1\",\n",
    "    \"two_year_recid\"  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data science, datasets are rarely tailored to specific applications. Instead, they typically originate from information collected over a certain period. It is the data scientist's responsibility to effectively utilize these datasets.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>[Remark 1.1]</b><br>\n",
    "In most real-world cases, the datasets you work with will contain artifacts like typos or missing data, which may need to be removed before using them in algorithms. In Pandas, missing data is represented as \"NaNs\" (Not a Number), though it applies to all missing objects, not just numbers.\n",
    "</div>\n",
    "\n",
    "Can you find a way to inspect your dataset and see if there are some missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Null count Before cleaning ==\n",
      "name                          0\n",
      "first                         0\n",
      "last                          0\n",
      "compas_screening_date         0\n",
      "sex                           0\n",
      "dob                           0\n",
      "age                           0\n",
      "age_cat                       0\n",
      "race                          0\n",
      "juv_fel_count                 0\n",
      "decile_score                  0\n",
      "juv_misd_count                0\n",
      "juv_other_count               0\n",
      "priors_count                  0\n",
      "days_b_screening_arrest       0\n",
      "c_jail_in                     0\n",
      "c_jail_out                    0\n",
      "c_case_number                 0\n",
      "c_offense_date              784\n",
      "c_arrest_date              5388\n",
      "c_days_from_compas            0\n",
      "c_charge_degree               0\n",
      "c_charge_desc                 5\n",
      "is_recid                      0\n",
      "r_case_number              3182\n",
      "r_charge_degree            3182\n",
      "r_days_from_arrest         4175\n",
      "r_offense_date             3182\n",
      "r_charge_desc              3228\n",
      "r_jail_in                  4175\n",
      "r_jail_out                 4175\n",
      "violent_recid              6172\n",
      "is_violent_recid              0\n",
      "vr_case_number             5480\n",
      "vr_charge_degree           5480\n",
      "vr_offense_date            5480\n",
      "vr_charge_desc             5480\n",
      "type_of_assessment            0\n",
      "decile_score.1                0\n",
      "score_text                    0\n",
      "screening_date                0\n",
      "v_type_of_assessment          0\n",
      "v_decile_score                0\n",
      "v_score_text                  0\n",
      "v_screening_date              0\n",
      "in_custody                    0\n",
      "out_custody                   0\n",
      "priors_count.1                0\n",
      "two_year_recid                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>...</th>\n",
       "      <th>score_text</th>\n",
       "      <th>screening_date</th>\n",
       "      <th>v_type_of_assessment</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6128</td>\n",
       "      <td>2493</td>\n",
       "      <td>3465</td>\n",
       "      <td>685</td>\n",
       "      <td>2</td>\n",
       "      <td>4830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>685</td>\n",
       "      <td>1087</td>\n",
       "      <td>1097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>anthony smith</td>\n",
       "      <td>michael</td>\n",
       "      <td>williams</td>\n",
       "      <td>2013-04-20</td>\n",
       "      <td>Male</td>\n",
       "      <td>1987-12-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-20</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-20</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>73</td>\n",
       "      <td>30</td>\n",
       "      <td>4997</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3532</td>\n",
       "      <td>3175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3421</td>\n",
       "      <td>30</td>\n",
       "      <td>6172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4117</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.534511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.641769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.246436</td>\n",
       "      <td>0.455120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.730938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.463599</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.488768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.743770</td>\n",
       "      <td>0.498022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name    first      last compas_screening_date   sex  \\\n",
       "count            6172     6172      6172                  6172  6172   \n",
       "unique           6128     2493      3465                   685     2   \n",
       "top     anthony smith  michael  williams            2013-04-20  Male   \n",
       "freq                3      127        73                    30  4997   \n",
       "mean              NaN      NaN       NaN                   NaN   NaN   \n",
       "std               NaN      NaN       NaN                   NaN   NaN   \n",
       "min               NaN      NaN       NaN                   NaN   NaN   \n",
       "25%               NaN      NaN       NaN                   NaN   NaN   \n",
       "50%               NaN      NaN       NaN                   NaN   NaN   \n",
       "75%               NaN      NaN       NaN                   NaN   NaN   \n",
       "max               NaN      NaN       NaN                   NaN   NaN   \n",
       "\n",
       "               dob          age  age_cat              race  juv_fel_count  \\\n",
       "count         6172  6172.000000     6172              6172    6172.000000   \n",
       "unique        4830          NaN        3                 6            NaN   \n",
       "top     1987-12-21          NaN  25 - 45  African-American            NaN   \n",
       "freq             5          NaN     3532              3175            NaN   \n",
       "mean           NaN    34.534511      NaN               NaN       0.059300   \n",
       "std            NaN    11.730938      NaN               NaN       0.463599   \n",
       "min            NaN    18.000000      NaN               NaN       0.000000   \n",
       "25%            NaN    25.000000      NaN               NaN       0.000000   \n",
       "50%            NaN    31.000000      NaN               NaN       0.000000   \n",
       "75%            NaN    42.000000      NaN               NaN       0.000000   \n",
       "max            NaN    96.000000      NaN               NaN      20.000000   \n",
       "\n",
       "        ...  score_text  screening_date  v_type_of_assessment  v_decile_score  \\\n",
       "count   ...        6172            6172                  6172     6172.000000   \n",
       "unique  ...           3             685                     1             NaN   \n",
       "top     ...         Low      2013-04-20      Risk of Violence             NaN   \n",
       "freq    ...        3421              30                  6172             NaN   \n",
       "mean    ...         NaN             NaN                   NaN        3.641769   \n",
       "std     ...         NaN             NaN                   NaN        2.488768   \n",
       "min     ...         NaN             NaN                   NaN        1.000000   \n",
       "25%     ...         NaN             NaN                   NaN        1.000000   \n",
       "50%     ...         NaN             NaN                   NaN        3.000000   \n",
       "75%     ...         NaN             NaN                   NaN        5.000000   \n",
       "max     ...         NaN             NaN                   NaN       10.000000   \n",
       "\n",
       "        v_score_text v_screening_date  in_custody out_custody priors_count.1  \\\n",
       "count           6172             6172        6172        6172    6172.000000   \n",
       "unique             3              685        1087        1097            NaN   \n",
       "top              Low       2013-04-20  2013-01-27  2020-01-01            NaN   \n",
       "freq            4117               30          19          46            NaN   \n",
       "mean             NaN              NaN         NaN         NaN       3.246436   \n",
       "std              NaN              NaN         NaN         NaN       4.743770   \n",
       "min              NaN              NaN         NaN         NaN       0.000000   \n",
       "25%              NaN              NaN         NaN         NaN       0.000000   \n",
       "50%              NaN              NaN         NaN         NaN       1.000000   \n",
       "75%              NaN              NaN         NaN         NaN       4.000000   \n",
       "max              NaN              NaN         NaN         NaN      38.000000   \n",
       "\n",
       "       two_year_recid  \n",
       "count     6172.000000  \n",
       "unique            NaN  \n",
       "top               NaN  \n",
       "freq              NaN  \n",
       "mean         0.455120  \n",
       "std          0.498022  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  \n",
       "\n",
       "[11 rows x 49 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.3.2: INFORMATION ABOUT TYPES AND NANs\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset.\n",
    "@post: Statistics and/or visualization on the presence of missing data in `df`.\n",
    "\"\"\"\n",
    "print(\"== Null count Before cleaning ==\")\n",
    "print(df.isnull().sum())\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>[Remark 1.2] Each problem has its own solution</b> <br>\n",
    "There exist numerous ways to deal with missing information and we will discuss the two main approaches:\n",
    "<ol>\n",
    "   <li> you remove rows or columns that contain missing data;\n",
    "   <li> or you replace NaNs with another value. The latter can be a fixed value or computed to be, e.g., the mean of all non-NaNs values. The topic of replacing missing data, also called imputation of missing values, is very broad and complex, and there is no global solution that applies everywhere. Maybe you can find one that works well here?\n",
    "</ol>\n",
    "    \n",
    "You **should** read more about how to imput missing value [here](https://scikit-learn.org/stable/modules/impute.html). However, you will not be evaluated on how sophisticated your handling of NaNs is so, for this hackathon, do not spend an unreasonable amount of time on the next cell.\n",
    "</div> \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 1.2] Handling missing data </b>  <br>\n",
    "Given the dataset and the amount / type of missing information, what strategy do you propose to follow regarding missing data (NaNs)? <br> You can choose one or many of the following:\n",
    "<ol>\n",
    "   <li> drop features (column) with missing information; \n",
    "   <li> drop samples (row) with missing information;\n",
    "   <li> replace missing information with interpolation / extrapolation / simple substitution / ...\n",
    "</ol>\n",
    "Justify briefly your choice.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compas_screening_date      6172\n",
       "sex                        6172\n",
       "dob                        6172\n",
       "age                        6172\n",
       "race                       6172\n",
       "juv_fel_count              6172\n",
       "juv_misd_count             6172\n",
       "juv_other_count            6172\n",
       "priors_count               6172\n",
       "days_b_screening_arrest    6172\n",
       "c_jail_in                  6172\n",
       "c_jail_out                 6172\n",
       "c_days_from_compas         6172\n",
       "c_charge_degree            6172\n",
       "is_violent_recid           6172\n",
       "type_of_assessment         6172\n",
       "screening_date             6172\n",
       "v_type_of_assessment       6172\n",
       "v_screening_date           6172\n",
       "in_custody                 6172\n",
       "out_custody                6172\n",
       "priors_count.1             6172\n",
       "two_year_recid             6172\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.3.3: Handling missing values\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset.\n",
    "@post: A pandas.DataFrame `df` containing the dataset with no missing values.\n",
    "\"\"\"\n",
    "old_df = df.copy()\n",
    "df = old_df[columns_to_keep]\n",
    "df.describe()\n",
    "df.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>1.4 - Feature engineering</b> <br>\n",
    "</font>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>[Remark 1.3] New features extraction</b> <br>\n",
    "In the present case, some features in the dataset still need to be reworked in order to provide meaningful information. For example, working with datetimes might not be easy.\n",
    "</div>\n",
    "\n",
    "You may want to somehow incorporate the information about date and time into the dataset in a more **intelligent** manner than it was before. Again, there can be multiple solutions, and we will propose you a very simple one.\n",
    "\n",
    "For example, what is most important to predict the likelihood of recidivism: the exact dates at which each defendant entered and left jail/custody or the time spent in jail/custody?\n",
    "\n",
    "Note: 1) you should apply your solution to all the \"date/time\" features you kept. There should at least be the one hinted above. 2) Pandas has a to_datetime function that should prove useful !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6172 entries, 0 to 7213\n",
      "Data columns (total 23 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   compas_screening_date    6172 non-null   object \n",
      " 1   sex                      6172 non-null   object \n",
      " 2   dob                      6172 non-null   object \n",
      " 3   age                      6172 non-null   int64  \n",
      " 4   race                     6172 non-null   object \n",
      " 5   juv_fel_count            6172 non-null   int64  \n",
      " 6   juv_misd_count           6172 non-null   int64  \n",
      " 7   juv_other_count          6172 non-null   int64  \n",
      " 8   priors_count             6172 non-null   int64  \n",
      " 9   days_b_screening_arrest  6172 non-null   float64\n",
      " 10  c_jail_in                6172 non-null   object \n",
      " 11  c_jail_out               6172 non-null   object \n",
      " 12  c_days_from_compas       6172 non-null   float64\n",
      " 13  c_charge_degree          6172 non-null   object \n",
      " 14  is_violent_recid         6172 non-null   int64  \n",
      " 15  type_of_assessment       6172 non-null   object \n",
      " 16  screening_date           6172 non-null   object \n",
      " 17  v_type_of_assessment     6172 non-null   object \n",
      " 18  v_screening_date         6172 non-null   object \n",
      " 19  in_custody               6172 non-null   object \n",
      " 20  out_custody              6172 non-null   object \n",
      " 21  priors_count.1           6172 non-null   int64  \n",
      " 22  two_year_recid           6172 non-null   int64  \n",
      "dtypes: float64(2), int64(8), object(13)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.4 : FEATURE ENGINEERING\n",
    "\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset\n",
    "@post: A pandas.DataFrame `df` containing the previous dataset with the new features you created.\n",
    "\"\"\"\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 1.3] New features </b>  <br>\n",
    "What features have you added? If a particular manipulation has been applied, please explain.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>1.5 - Sensitive features</b> <br>\n",
    "</font>\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>[Remark 1.4] Sensitive features</b> <br>\n",
    "At this stage of the Hackathon, you still have two sensitive features, the sex attribute and the race attribute. As the end goal is to build a fair learning algorithm, you should not reasonably use these two features to determine if there is a risk of recidivism of the defendant.\n",
    "</div>\n",
    "\n",
    "To check if your learning techniques are unfair to particular subgroups of these features, you should **remove both features from the dataset while keeping them aside** to analyze the fairness of our learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Other' 'African-American' 'African-American' ... 'Other'\n",
      " 'African-American' 'Hispanic']\n",
      "[3 0 0 ... 3 0 4]\n",
      "['Male' 'Male' 'Male' ... 'Male' 'Female' 'Female']\n",
      "[0 0 0 ... 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>...</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>type_of_assessment</th>\n",
       "      <th>screening_date</th>\n",
       "      <th>v_type_of_assessment</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>Male</td>\n",
       "      <td>1971-08-22</td>\n",
       "      <td>44</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>Male</td>\n",
       "      <td>1974-07-23</td>\n",
       "      <td>41</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-07-17</td>\n",
       "      <td>23</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-03-25</td>\n",
       "      <td>23</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>2014-02-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1958-10-01</td>\n",
       "      <td>57</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>1982-11-17</td>\n",
       "      <td>33</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>Female</td>\n",
       "      <td>1992-12-18</td>\n",
       "      <td>23</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6172 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     compas_screening_date     sex         dob  age              race  \\\n",
       "0               2013-08-14    Male  1947-04-18   69             Other   \n",
       "1               2013-01-27    Male  1982-01-22   34  African-American   \n",
       "2               2013-04-14    Male  1991-05-14   24  African-American   \n",
       "5               2013-11-30    Male  1971-08-22   44             Other   \n",
       "6               2014-02-19    Male  1974-07-23   41         Caucasian   \n",
       "...                    ...     ...         ...  ...               ...   \n",
       "7209            2013-11-23    Male  1992-07-17   23  African-American   \n",
       "7210            2014-02-01    Male  1993-03-25   23  African-American   \n",
       "7211            2014-01-14    Male  1958-10-01   57             Other   \n",
       "7212            2014-03-09  Female  1982-11-17   33  African-American   \n",
       "7213            2014-06-30  Female  1992-12-18   23          Hispanic   \n",
       "\n",
       "      juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n",
       "0                 0               0                0             0   \n",
       "1                 0               0                0             0   \n",
       "2                 0               0                1             4   \n",
       "5                 0               0                0             0   \n",
       "6                 0               0                0            14   \n",
       "...             ...             ...              ...           ...   \n",
       "7209              0               0                0             0   \n",
       "7210              0               0                0             0   \n",
       "7211              0               0                0             0   \n",
       "7212              0               0                0             3   \n",
       "7213              0               0                0             2   \n",
       "\n",
       "      days_b_screening_arrest  ... c_days_from_compas c_charge_degree  \\\n",
       "0                        -1.0  ...                1.0               F   \n",
       "1                        -1.0  ...                1.0               F   \n",
       "2                        -1.0  ...                1.0               F   \n",
       "5                         0.0  ...                0.0               M   \n",
       "6                        -1.0  ...                1.0               F   \n",
       "...                       ...  ...                ...             ...   \n",
       "7209                     -1.0  ...                1.0               F   \n",
       "7210                     -1.0  ...                1.0               F   \n",
       "7211                     -1.0  ...                1.0               F   \n",
       "7212                     -1.0  ...                1.0               M   \n",
       "7213                     -2.0  ...                2.0               F   \n",
       "\n",
       "      is_violent_recid  type_of_assessment  screening_date  \\\n",
       "0                    0  Risk of Recidivism      2013-08-14   \n",
       "1                    1  Risk of Recidivism      2013-01-27   \n",
       "2                    0  Risk of Recidivism      2013-04-14   \n",
       "5                    0  Risk of Recidivism      2013-11-30   \n",
       "6                    0  Risk of Recidivism      2014-02-19   \n",
       "...                ...                 ...             ...   \n",
       "7209                 0  Risk of Recidivism      2013-11-23   \n",
       "7210                 0  Risk of Recidivism      2014-02-01   \n",
       "7211                 0  Risk of Recidivism      2014-01-14   \n",
       "7212                 0  Risk of Recidivism      2014-03-09   \n",
       "7213                 0  Risk of Recidivism      2014-06-30   \n",
       "\n",
       "     v_type_of_assessment v_screening_date  in_custody out_custody  \\\n",
       "0        Risk of Violence       2013-08-14  2014-07-07  2014-07-14   \n",
       "1        Risk of Violence       2013-01-27  2013-01-26  2013-02-05   \n",
       "2        Risk of Violence       2013-04-14  2013-06-16  2013-06-16   \n",
       "5        Risk of Violence       2013-11-30  2013-11-30  2013-12-01   \n",
       "6        Risk of Violence       2014-02-19  2014-03-31  2014-04-18   \n",
       "...                   ...              ...         ...         ...   \n",
       "7209     Risk of Violence       2013-11-23  2013-11-22  2013-11-24   \n",
       "7210     Risk of Violence       2014-02-01  2014-01-31  2014-02-02   \n",
       "7211     Risk of Violence       2014-01-14  2014-01-13  2014-01-14   \n",
       "7212     Risk of Violence       2014-03-09  2014-03-08  2014-03-09   \n",
       "7213     Risk of Violence       2014-06-30  2015-03-15  2015-03-15   \n",
       "\n",
       "     priors_count.1  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 4  \n",
       "5                 0  \n",
       "6                14  \n",
       "...             ...  \n",
       "7209              0  \n",
       "7210              0  \n",
       "7211              0  \n",
       "7212              3  \n",
       "7213              2  \n",
       "\n",
       "[6172 rows x 22 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.5 : SENSITIVE FEATURES\n",
    "\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset with sensitive features\n",
    "@post: A pandas.DataFrame `df` containing the dataset without sensitive features and separate numpy arrays for each sensitive feature \n",
    "as well as the true label array `y`.\n",
    "\"\"\"\n",
    "\n",
    "# Use the dictionaries below to encode numerically the sensitive features.\n",
    "race = df[\"race\"].to_numpy()\n",
    "print(race)\n",
    "race_map = {\n",
    "    \"African-American\": 0,\n",
    "    \"Caucasian\": 1,\n",
    "    \"Asian\": 2,\n",
    "    \"Other\": 3,\n",
    "    \"Hispanic\": 4,\n",
    "    \"Native American\": 5,\n",
    "}\n",
    "race_mapped = np.array([race_map[i] for i in race]) #TP : Replacing every race by its numerical mapping\n",
    "print(race_mapped)\n",
    "\n",
    "sex = df[\"sex\"].to_numpy()\n",
    "print(sex)\n",
    "sex_map = {\"Male\": 0, \"Female\": 1}\n",
    "sex_mapped = np.array([sex_map[i] for i in sex])  #TP : Replacing every sex by its numerical mapping\n",
    "print(sex_mapped)\n",
    "\n",
    "\n",
    "# As you approach the last step of the preprocessing, you should also store the target variable and remove it from the dataframe.\n",
    "# It is good practice to remove it just before the scaling so that its dimension corresponds to the number of data points in `df`.\n",
    "y = df[\"two_year_recid\"].astype(float).values\n",
    "df.drop(columns=[\"two_year_recid\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>1.6 - Scaling the dataset</b> <br>\n",
    "</font>\n",
    "\n",
    "***Standardizing*** is important when you work with data because it allows data to be compared with one another.\n",
    "\n",
    "$z$ is the standard score of a population $x$. It can be computed as follows:\n",
    "$$z = \\frac{x-\\mu}{\\sigma}$$\n",
    "with $\\mu$ the mean of the population and $\\sigma$ the standard deviation of the population.\n",
    "\n",
    "Please consult [Wikipedia](https://en.wikipedia.org/wiki/Standard_score) for further information about the standardization.\\\n",
    "Be careful to use the same formula as us, check in `scikit-learn` and check the already existing imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6172 entries, 0 to 7213\n",
      "Data columns (total 23 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   compas_screening_date    6172 non-null   object \n",
      " 1   sex                      6172 non-null   object \n",
      " 2   dob                      6172 non-null   object \n",
      " 3   age                      6172 non-null   int64  \n",
      " 4   race                     6172 non-null   object \n",
      " 5   juv_fel_count            6172 non-null   int64  \n",
      " 6   juv_misd_count           6172 non-null   int64  \n",
      " 7   juv_other_count          6172 non-null   int64  \n",
      " 8   priors_count             6172 non-null   int64  \n",
      " 9   days_b_screening_arrest  6172 non-null   float64\n",
      " 10  c_jail_in                6172 non-null   object \n",
      " 11  c_jail_out               6172 non-null   object \n",
      " 12  c_days_from_compas       6172 non-null   float64\n",
      " 13  c_charge_degree          6172 non-null   object \n",
      " 14  is_violent_recid         6172 non-null   int64  \n",
      " 15  type_of_assessment       6172 non-null   object \n",
      " 16  screening_date           6172 non-null   object \n",
      " 17  v_type_of_assessment     6172 non-null   object \n",
      " 18  v_screening_date         6172 non-null   object \n",
      " 19  in_custody               6172 non-null   object \n",
      " 20  out_custody              6172 non-null   object \n",
      " 21  priors_count.1           6172 non-null   int64  \n",
      " 22  two_year_recid           6172 non-null   int64  \n",
      "dtypes: float64(2), int64(8), object(13)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.534511</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.091218</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>3.246436</td>\n",
       "      <td>-1.740279</td>\n",
       "      <td>24.903273</td>\n",
       "      <td>0.112119</td>\n",
       "      <td>3.246436</td>\n",
       "      <td>0.455120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.730938</td>\n",
       "      <td>0.463599</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>0.470731</td>\n",
       "      <td>4.743770</td>\n",
       "      <td>5.084709</td>\n",
       "      <td>276.812982</td>\n",
       "      <td>0.315539</td>\n",
       "      <td>4.743770</td>\n",
       "      <td>0.498022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9485.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  juv_fel_count  juv_misd_count  juv_other_count  \\\n",
       "count  6172.000000    6172.000000     6172.000000      6172.000000   \n",
       "mean     34.534511       0.059300        0.091218         0.110661   \n",
       "std      11.730938       0.463599        0.497872         0.470731   \n",
       "min      18.000000       0.000000        0.000000         0.000000   \n",
       "25%      25.000000       0.000000        0.000000         0.000000   \n",
       "50%      31.000000       0.000000        0.000000         0.000000   \n",
       "75%      42.000000       0.000000        0.000000         0.000000   \n",
       "max      96.000000      20.000000       13.000000         9.000000   \n",
       "\n",
       "       priors_count  days_b_screening_arrest  c_days_from_compas  \\\n",
       "count   6172.000000              6172.000000         6172.000000   \n",
       "mean       3.246436                -1.740279           24.903273   \n",
       "std        4.743770                 5.084709          276.812982   \n",
       "min        0.000000               -30.000000            0.000000   \n",
       "25%        0.000000                -1.000000            1.000000   \n",
       "50%        1.000000                -1.000000            1.000000   \n",
       "75%        4.000000                -1.000000            1.000000   \n",
       "max       38.000000                30.000000         9485.000000   \n",
       "\n",
       "       is_violent_recid  priors_count.1  two_year_recid  \n",
       "count       6172.000000     6172.000000     6172.000000  \n",
       "mean           0.112119        3.246436        0.455120  \n",
       "std            0.315539        4.743770        0.498022  \n",
       "min            0.000000        0.000000        0.000000  \n",
       "25%            0.000000        0.000000        0.000000  \n",
       "50%            0.000000        1.000000        0.000000  \n",
       "75%            0.000000        4.000000        1.000000  \n",
       "max            1.000000       38.000000        1.000000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.6 : SCALE THE DATASET\n",
    "\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset\n",
    "@post: A pandas.DataFrame `df` containing the standardized dataset\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def scale_dataset(df):\n",
    "    # Modify here...\n",
    "    return df\n",
    "\n",
    "\n",
    "X = scale_dataset(df)\n",
    "X.info()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=7 color=#009999> <b>PART 2 - Data Exploration</b> </font> <br><br>\n",
    "\n",
    "<font size=5 color=#009999> <b>2.1 - Feature visualization</b> <br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the dataset balanced in terms of sensitive groups ?\n",
    "It's good practice to check this to better understand the contents of our dataset.\n",
    "Indeed, if the training dataset is severely imbalanced, our learning algorithm may perform better for over-represented groups than for under-represented groups. Moreover, our goal is for the model to perform equally well across all groups.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 2.1] (Im)Balanced dataset ? </b>  <br>\n",
    "Is the dataset imbalanced ? What could be the consequences in terms of fairness i.e. in terms of the model performing equally well across all groups ?\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°2.1.1: (Im)Balanced dataset ?\n",
    "\n",
    "@pre:  A pandas.DataFrame `X` containing the dataset\n",
    "@post: A pie chart plot representing the repartition of race groups in the dataset.\n",
    "\"\"\"\n",
    "\n",
    "# As the race group was previously removed, we can temporarily add it back, using the following map.\n",
    "race_reverse_map = {v: k for k, v in race_map.items()}\n",
    "\n",
    "\n",
    "X = X.drop(columns=[\"race\"])  # Remove the race group again after doing the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "In order to check to the important features in our dataset, we can compute and plot (see e.g. `sns.heatmap`) the correlation matrix, as a tool to visually show all the correlation between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2013-08-14'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure(data\u001b[38;5;241m=\u001b[39m[heat], layout\u001b[38;5;241m=\u001b[39mlayout)\n\u001b[1;32m     34\u001b[0m     fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 36\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpearson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m plot_correlation_matrix(df)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/pandas/core/frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/pandas/core/frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/pandas/core/internals/managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/pandas/core/internals/managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2013-08-14'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°2.1.2 : Correlation matrix\n",
    "\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset\n",
    "@post: A visualization of the correlation matrix between features.\n",
    "\"\"\"\n",
    "\n",
    "# TODO : vérifier la corrélation pour jarter des features\n",
    "\n",
    "def plot_correlation_matrix(data):\n",
    "\n",
    "    X    = [label for label in data]\n",
    "    N    = data.shape[1]\n",
    "    corr = (data.corr()).values\n",
    "\n",
    "    # Display the correlation in cells\n",
    "    hovertext      = [ [f\"corr({X[i]}, {X[j]})= {corr[i][j]:.2f}\" for j in range(N)] for i in range(N) ]\n",
    "    sns_colorscale = [ [0.0, \"#3f7f93\"],   [0.071, \"#5890a1\"], [0.143, \"#72a1b0\"], [0.214, \"#8cb3bf\"],\n",
    "                    [0.286, \"#a7c5cf\"], [0.357, \"#c0d6dd\"], [0.429, \"#dae8ec\"], [0.5, \"#f2f2f2\"], \n",
    "                    [0.571, \"#f7d7d9\"], [0.643, \"#f2bcc0\"], [0.714, \"#eda3a9\"], [0.786, \"#e8888f\"], \n",
    "                    [0.857, \"#e36e76\"], [0.929, \"#de535e\"], [1.0, \"#d93a46\"] ]\n",
    "\n",
    "\n",
    "    heat   = go.Heatmap(z = data.corr(), x = X, y = X, zmin = -1, zmax = 1, xgap = 1, ygap = 1,\n",
    "                        colorscale = sns_colorscale, colorbar_thickness = 20, colorbar_ticklen = 3,\n",
    "                        hovertext = hovertext, hoverinfo = \"text\" )\n",
    "    title  = \"Correlation Matrix\"\n",
    "\n",
    "    layout = go.Layout(title_text = title, title_x = 0.5, width = 600, height = 600,\n",
    "        xaxis_showgrid = False, yaxis_showgrid = False, yaxis_autorange = \"reversed\")\n",
    "\n",
    "\n",
    "    fig = go.Figure(data=[heat], layout=layout)\n",
    "    fig.show()\n",
    "\n",
    "corr_matrix = df.corr(method='pearson')\n",
    "plot_correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>2.2 Principal Component Analysis</b> <br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is often considered as the simplest and most fundamental technique used in dimensionality reduction. Remember that PCA is essentially the rotation of coordinate axes, chosen such that each successful axis captures or preserves as much variance as possible. If the algorithm returns a new system coordinates of the same dimension as the input, we can keep only the axis corresponding to the 3 largest singular values and project data on this coordinates system to perform the visualization.\n",
    "\n",
    "To vizualize the importance of features, we can extract the PCA loadings. These are indicators of the correlation between components and original features. The value of loadings is contained between -1 and 1. The more the value goes toward those boundaries, the more the feature influences the choice of component.We propose to perform a 2-dimensional PCA and then to add the loadings in vector form to the figure to obtain what is called a biplot.\n",
    "\n",
    "The biplot visualization function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°2.2.1 : Principal Component Analysis (2D)\n",
    "\n",
    "@pre:  A pandas.DataFrame `X` containing the dataset and labels `y`\n",
    "@post: A PCA visualization in 2D where points are colored with respect to true labels `y`\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def biplot_visualization(X, y, columns=None):\n",
    "    \"\"\"\n",
    "    Plot a biplot graph: the scaled data after applying a 2D PCA with loadings in vector forms.\n",
    "\n",
    "    :param pca: PCA object\n",
    "    :param X: a n by m matrix (or DataFrame), containing the input prior to the PCA transformation\n",
    "    :param y: a vector of length n containing the target\n",
    "    :param columns: a list of length m contained the names of the columns\n",
    "        If not given, X.columns will be used\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=2)\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "    columns = (\n",
    "        columns\n",
    "        if columns is not None\n",
    "        else X.columns\n",
    "        if isinstance(X, pd.DataFrame)\n",
    "        else [f\"Feature {i+1}\" for i in range(X.shape[1])]\n",
    "    )\n",
    "\n",
    "    # Normalize data for scaling\n",
    "    X_normalized = X / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "    df = pd.DataFrame(data=X_normalized, columns=[\"PC1\", \"PC2\"])\n",
    "\n",
    "    # Prepare loadings (vector components)\n",
    "    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "    loadings_df = pd.DataFrame(loadings, columns=[\"PC1\", \"PC2\"], index=columns)\n",
    "\n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(x=df[\"PC1\"], y=df[\"PC2\"], hue=y, palette=\"viridis\", s=70, alpha=0.7)\n",
    "\n",
    "    # Add vectors for loadings\n",
    "    for index, row in loadings_df.iterrows():\n",
    "        plt.arrow(\n",
    "            0,\n",
    "            0,\n",
    "            row.PC1,\n",
    "            row.PC2,\n",
    "            color=\"red\",\n",
    "            alpha=0.7,\n",
    "            head_width=0.02,\n",
    "            head_length=0.03,\n",
    "        )\n",
    "        plt.text(\n",
    "            row.PC1 * 1.1,\n",
    "            row.PC2 * 1.1,\n",
    "            index,\n",
    "            color=\"black\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    # Labels and limits\n",
    "    plt.title(\"Biplot Visualization\", fontsize=14)\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.axvline(0, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(title=\"Classes\", loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# biplot_visualization(X, y, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, you are asked to perform a 3 components PCA and plot it using Plotly.\n",
    "<div class=\"alert alert-danger\">\n",
    " Note: On certain versions of Firefox, the 3D scatter function of plotly may have some issues.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCELL N°2.2.2 : Principal Component Analysis (3D)\\n\\n@pre:  A pandas.DataFrame `X` containing the dataset and labels `y`\\n@post: A PCA visualization in 3D where points are colored with respect to true labels `y`\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°2.2.2 : Principal Component Analysis (3D)\n",
    "\n",
    "@pre:  A pandas.DataFrame `X` containing the dataset and labels `y`\n",
    "@post: A PCA visualization in 3D where points are colored with respect to true labels `y`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 2.2] Principal Component Analysis </b>  <br>\n",
    "Do all features have the same importance? If no, which features are less important, and why? You can use all other graphs from the visualization part to justify your answer.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=7 color=#009999> <b>PART 3 - Clustering</b> </font> <br><br>\n",
    "\n",
    "<font size=4 color=#009999> <b>ABCs of Clustering</b> <br>\n",
    "Clustering can be defined as the task of *grouping* objects from a set $S$ (here, each row/observation is an object) in such a way that objects assigned to the same group (called cluster) are more **similar** (or less **distant**) with respect to each other (in some sense) than to those assigned to the other groups. Usually, we would like to divide our objects into $K$ groups.\n",
    "\n",
    "As such, clustering reduces to finding, among all $K$-partitions possible of $S$, the partition $\\mathcal{P}$ that minimizes some error criterion $f(\\mathcal{P})$. Each object will be assigned a cluster, $C_i$, and each cluster will have its centroid $c_i$ the distance between **any object** in $C_i$ to centroid $c_i$ is **always smaller** that the distance to any other centroid. In other words, each object is assigned to the cluster whose centroid is the closest.\n",
    "\n",
    "\n",
    "A mathematical formulation of the problem could be the following, $$ \\boxed{\\min_{(C_1,\\dots,C_K) \\,\\in\\, \\mathcal{P}}\\,f(C_1,\\dots,C_K) = \\sum_{i = 1}^{K}\\,\\sum_{x \\in C_i}\\,\\Delta(x,c_i)}$$\n",
    "\n",
    "where $\\Delta(x,c_i)$ denotes the distance between object $x$ and centroid $c_i$.\n",
    "\n",
    "<br>\n",
    "<font size=5 color=#009999>\n",
    "EXAMPLE OF SEPARATING OBJECTS INTO 10 CLUSTERS\n",
    "</font> <br> <br>\n",
    "\n",
    "**First**, let us imagine the following 2D dataset.\n",
    "\n",
    "<img src=\"Imgs/10-partitions-data.svg\" width = \"250\">\n",
    "\n",
    "**Then**, a 10-partition is defined by the position of the centroids, one for each cluster. Below, you can observe four examples of (random) centroids localizations (stars).\n",
    "\n",
    "<img src=\"Imgs/10-partitions-chose-centroids.svg\" width = \"1000\">\n",
    "\n",
    "**Next**, the regions are colored based on their closest centroid. Here, we take the distance to be the Euclidean distance.\n",
    "\n",
    "<img src=\"Imgs/10-partitions-centroids.svg\" width = \"1000\">\n",
    "\n",
    "**Finally**, data points (objects) are colored based in the region they are in.\n",
    "\n",
    "<img src=\"Imgs/10-partitions-clusters.svg\" width = \"1000\">\n",
    "\n",
    "<font size=5 color=#009999> <b>3.1 - K-Means</b> <br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCELL N°3.1.1 : GROUND TRUTH\\n\\n@pre:  A pandas.DataFrame `X` containing the dataset and labels `y`\\n@post: A 80/20 split of your dataset in train and test sets.\\n'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°3.1.1 : GROUND TRUTH\n",
    "\n",
    "@pre:  A pandas.DataFrame `X` containing the dataset and labels `y`\n",
    "@post: A 80/20 split of your dataset in train and test sets.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 3.1] Number of clusters </b>  <br>\n",
    "    Accounting for all features, what do you think is the ideal number of clusters? What will happen if too many or even too few clusters are chosen?\n",
    "</div>\n",
    "\n",
    "Now that your dataset is divided into a train and a test set, use the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\">KMeans</a> algorithm from `scikit-learn` to apply the clustering on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°3.1.2 : K-Means\n",
    "\n",
    "@pre:  A split of your dataset: X_train, X_test, y_train, y_test\n",
    "@post: A split of your dataset in train and test sets.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_and_predict(model, X_train, X_test):\n",
    "    \"\"\"Trains the clustering model on the training data and predict the clusters for both training and test data.\n",
    "\n",
    "    Parameters:\n",
    "    model (sklearn or similar clustering model): The clustering algorithm that has a fit_predict method and a predict method.\n",
    "    X_train (array-like, shape (n_samples, n_features)): The training data to fit the model on.\n",
    "    X_test (array-like, shape (n_samples, n_features)): The test data to predict the clusters for.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two arrays:\n",
    "        - train_clusters (array): Cluster labels for the training data.\n",
    "        - test_clusters (array): Cluster labels for the test data.\n",
    "    \"\"\"\n",
    "    train_clusters = ...  # TODO\n",
    "    test_clusters = ...  # TODO\n",
    "    return train_clusters, test_clusters\n",
    "\n",
    "\n",
    "def compute_y_pred(model, X_train, X_test, y_train):\n",
    "    \"\"\"Compute the predicted labels for the test data based on the clustering model.\n",
    "\n",
    "    This function assigns a predicted label to each sample in the test set by:\n",
    "    1. Training the model on the training data using the previous function.\n",
    "    2. Assigning the majority class from the training labels to each cluster.\n",
    "    3. Using the cluster assignments from the test data to assign predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    model (sklearn or similar clustering model): The trained clustering model with an `n_clusters` attribute.\n",
    "    X_train (array-like, shape (n_samples, n_features)): The training data used to fit the model.\n",
    "    X_test (array-like, shape (n_samples, n_features)): The test data to predict labels for.\n",
    "    y_train (array-like, shape (n_samples,)): The true labels of the training data.\n",
    "\n",
    "    Returns:\n",
    "    np.array: An array of predicted labels for the test data based on the majority class in each cluster.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    train_clusters, test_clusters = train_and_predict(model, X_train, X_test)\n",
    "    df = pd.DataFrame({\"cluster\": train_clusters, \"target\": y_train})\n",
    "\n",
    "    for cluster in range(model.n_clusters):\n",
    "        majority_class = df[df[\"cluster\"] == cluster][\"target\"].mode()[0]\n",
    "        mapping[cluster] = majority_class\n",
    "\n",
    "    y_pred = ...  # TODO\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def compute_metrics(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Computes various evaluation metrics for the clustering model.\n",
    "\n",
    "    Parameters:\n",
    "    model (sklearn or similar clustering model): The trained clustering model with an `n_clusters` attribute.\n",
    "    X_train (array-like, shape (n_samples, n_features)): The training data used to fit the model.\n",
    "    X_test (array-like, shape (n_samples, n_features)): The test data to predict labels for.\n",
    "    y_train (array-like, shape (n_samples,)): The true labels of the training data.\n",
    "    y_test (array-like, shape (n_samples,)): The true labels of the test data.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the computed metrics:\n",
    "        - \"n_clusters\": The number of clusters in the model.\n",
    "        - \"Accuracy\": The accuracy of the model on the test data.\n",
    "        - \"F1-Score\": The F1-score of the model on the test data.\n",
    "        - \"Precision\": The precision of the model on the test data.\n",
    "        - \"Recall\": The recall of the model on the test data.\n",
    "        - \"Silhouette Score\": The silhouette score of the clustering on the test data.\n",
    "    \"\"\"\n",
    "    y_pred = compute_y_pred(model, X_train, X_test, y_train)\n",
    "    accuracy = ...  # TODO\n",
    "    f1 = ...  # TODO\n",
    "    precision, recall, _, _ = ...  # TODO\n",
    "    sil_score = ...  # TODO\n",
    "    return {\n",
    "        \"n_clusters\": ...,  # TODO\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Silhouette Score\": sil_score,\n",
    "    }\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=random_seed)\n",
    "# results = compute_metrics(kmeans, X_train, y_train, X_test, y_test)\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> <b>3.2 - Results Analysis</b> <br>\n",
    "</font>\n",
    "\n",
    "In this section, we adress the difficult task of evaluating the performance of the clustering algorithm.\n",
    "\n",
    "<font size=3 color=#009999> <b>3.2.1 - Quality of the clustering</b> <br>\n",
    "</font>\n",
    "The silhouette score is a measure of how close each point in one cluster is to points in the neighboring clusters. The [mean silhouette score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) is an average of the silhouette score for each point and provides a way to measure the quality of the clustering.\n",
    "\n",
    "The best value is 1 and the worst value is -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°3.2.1 : Silhouette Score\n",
    "\n",
    "@pre:  A split of your dataset: X_train, X_test, y_train, y_test\n",
    "@post: A \"Mean Silhouette Score versus Number of Clusters\" plot\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>3.2.2 - Purity and entropy of a clustering</b> <br>\n",
    "</font>\n",
    "\n",
    "### Purity\n",
    "\n",
    "Purity measures how well a cluster contains points from a single class. A cluster with high purity mostly contains points from one class.\n",
    "\n",
    "**Example:** Imagine you are grouping fruits based on their shape, but you also have information about their color. If a group contains mostly red apples, that group has high purity. However, if you find a few green apples or pears in the group, the purity decreases. In this case, high purity means the majority of fruits share both shape and color consistency.\n",
    "\n",
    "Formula:\n",
    "$$\n",
    "\\text{Purity } = \\frac{1}{N} \\sum_{i = 1}^k \\max_j n_{i,j}\n",
    "$$\n",
    "where:\n",
    "- $N = $ total number of points,\n",
    "- $k = $ number of clusters,\n",
    "- $n_{i,j} = $​ number of points from class $j$ in cluster $i$,\n",
    "- $\\max_j n_{i,j} = $ number of points from the most common class in cluster $i$.\n",
    "\n",
    "\n",
    "### Entropy\n",
    "\n",
    "Entropy measures how mixed the classes are within a cluster. Low entropy means most points in a cluster belong to the same class. High entropy means points are more evenly distributed across different classes.\n",
    "\n",
    "**Example:** Consider a fruit basket that is mostly filled with red apples, with only a few bananas and oranges. Since the basket is dominated by one type of fruit, it has low entropy. In contrast, if the basket contains an equal mix of apples, bananas, and oranges, the distribution is more random, resulting in high entropy. This even distribution means it is harder to predict the dominant fruit just by looking at the basket.\n",
    "\n",
    "***Formula for a single cluster:***\n",
    "$$\n",
    "E_i = -\\sum_{j=1}^{C} p_{ij} \\log_2(p_{ij})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $C = $ number of classes,\n",
    "- $p_{i,j} = $ proportion of points from class jj in cluster ii.\n",
    "\n",
    "The overall entropy is the weighted average across all clusters:\n",
    "\n",
    "$$\n",
    "\\text{Entropy} = \\frac{1}{N} \\sum_{i=1}^{k} n_i \\cdot E_i\n",
    "$$\n",
    "\n",
    "Where $n_i$​ is the number of points in cluster $i$.\n",
    "\n",
    "A good clustering aims for both high purity (most points in a cluster belong to one class) and low entropy (each cluster contains little class mixing).\n",
    "    \n",
    "<div class=\"alert alert-danger\">\n",
    " If this makes it easier for you to implement purity and entropy, you can modify the previously defined function `compute_metrics` to also return in the results dictionary the purity, the entropy or any other metric that you may want to use later on.\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    " Compared to the silhouette score which is computed using only the features, purity and entropy are metrics computed using the true label `y`. Do not forget to compute these metrics on a test set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°3.2.2 : Purity and Entropy\n",
    "\n",
    "@pre:  A split of your dataset: X_train, X_test, y_train, y_test\n",
    "@post: A \"Purity/Entropy versus Number of Clusters\" plot. There should be two curves, one for the purity and one for the entropy.\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 3.2] Quality of the clustering </b>  <br>\n",
    "    You considered three different measures for the quality of the clustering: the first one is the silhouette score and is oblivious to the true labels: it is a truly unsupervised metric. The second and third metric use the true label to assess the quality of the clustering. Based on this observation,\n",
    "    \n",
    "1. Comment on the evolution of each metric according to the number of clusters.\n",
    "2. Comment on what do you now think is the ideal number of clusters ?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=7 color=#009999> <b>PART 4 - Fairness metrics</b> </font> <br><br>\n",
    "\n",
    "Congratulations for reaching this far ! So far, you have thoroughly analyzed a sensitive dataset, you cleaned it and focused on what you believe were useful features for predicting recidivism. You then used the K-Means algorithm to have your own recidivism predictor.\n",
    "\n",
    "Because of the sensitivity of the dataset and its potential negative impact on certain parts of the population, you should now assess its fairness with respect to each gender and race group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>4.1 False Positive Rate</b> <br>\n",
    "</font>\n",
    "\n",
    "The false positive rate (FPR) is a performance metric used to evaluate the accuracy of a machine learning model, particularly in binary classification tasks. It refers to the proportion of actual negative instances (people that did not recidivate) that are incorrectly classified as positive. A lower FPR indicates that the model is better at identifying negative cases.\n",
    "\n",
    "A fair model would have the same FPR across all groups.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    " As for the purity and entropy metrics, the false positive rate metric uses the true labels, you should therefore make a train/test split before hand.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°4.1 False Positive Rate\n",
    "\n",
    "@pre:  A split of your dataset: X_train, X_test, y_train, y_test\n",
    "@post: A \"False Positive Rate vs Number of Clusters\" plot for each group\n",
    "\"\"\"\n",
    "\n",
    "# Because the dataset is imbalanced, we will repartition our dataset into three race groups: African-American, Caucasian and Other.\n",
    "group_labels = np.where(race == 0, 0, np.where(race == 1, 1, 2))\n",
    "\n",
    "# X_train, X_test, y_train, y_test, group_train, group_val = train_test_split(\n",
    "#     X, y, group_labels, test_size=0.2, random_state=random_seed\n",
    "# )\n",
    "\n",
    "# Doing so, you can now use X_test[group_val == i] to get the test points with race i.\n",
    "\n",
    "\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"False Positive Rate\")\n",
    "plt.title(\"False Positive Rate vs. Number of Clusters\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>4.2 Demographic Parity</b> <br>\n",
    "</font>\n",
    "Demographic parity is a fairness metric aimed at ensuring that a machine learning model’s predictions do not depend on membership in a sensitive group. Specifically, demographic parity is achieved when the likelihood of a prediction is independent of sensitive group membership. In binary classification, demographic parity requires equal selection rates across groups.\n",
    "\n",
    "In our case, perfect demographic parity means that there is the exact same proportion of “bail denied” in each race group. A fair model would have the same Demographic Parity value across all groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°4.2 Demographic Parity\n",
    "\n",
    "@pre:  A split of your dataset: X_train, X_test, y_train, y_test\n",
    "@post: A \"Demographic Parity vs Number of Clusters\" plot\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# We provide the function below to compute demographic parity\n",
    "def compute_demographic_parity(y_pred, group_labels):\n",
    "    unique_groups = np.unique(group_labels)\n",
    "    demographic_parity = {}\n",
    "\n",
    "    for group in unique_groups:\n",
    "        # Create a boolean mask for the current group\n",
    "        group_mask = group_labels == group\n",
    "\n",
    "        # Calculate the proportion of positive predictions for the group\n",
    "        group_pred = y_pred[group_mask]\n",
    "        positive_rate = np.mean(group_pred == 1)\n",
    "\n",
    "        demographic_parity[group] = positive_rate\n",
    "\n",
    "    return demographic_parity\n",
    "\n",
    "\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Demographic Parity\")\n",
    "plt.title(\"Demographic Parity vs. Number of Clusters\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 4.1] Fairness of your model </b>  <br>\n",
    "    You considered two different measures for the fairness of your model and checked for various variants of your algorithm (number of clusters) the value of these fairness metrics.\n",
    "\n",
    "Is your algorithm unfair ? If yes, which ethnic group is penalized by the unfairness of your model ?\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 4.2] Presence of the sensitive features in the dataset [BONUS]</b> <br> \n",
    "In Cell 1.5, you removed the sensitive features from your dataset before building your algorithm. Yet, you may have noticed unfairness in your algorithm.\n",
    "\n",
    "1. Provide reasons why it is not necessarily enough to remove sensitive features from your dataset if you want to have fair predictions.\n",
    "2. Compute FPR and Demographic Parity for your algorithm when trained on the full dataset. Is the fairness of your classifier worse ?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for the BONUS question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=7 color=#009999> <b>PART 5 - Visualization </b> </font> <br><br>\n",
    "\n",
    "<font size=5 color=#009999> <b>5.1 Visualize your results</b> <br>\n",
    "</font>\n",
    "In the last cell, you can create the figure of your choice to visualize your results. You can be as creative as you want as long as you only use one figure (with potentially more than one plot).\n",
    "\n",
    "You will be evaluated on the clarity of your figure. You should ask yourself the following question while creating it: \"Is the message I am trying to convey clear enough so that a student from another group can take a quick look and understand it directly ?\" If the answer is positive, it's probably a great plot !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for the VISUALIZATION question."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
